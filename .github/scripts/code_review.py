#!/usr/bin/env python3

import os
import sys
import subprocess
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from github import Github
from github.PullRequest import PullRequest

def get_changed_files(pr: PullRequest) -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ PR."""
    return [file.filename for file in pr.get_files()]

def run_ruff_check(file_path: str) -> Tuple[str, bool]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç ruff –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            ["ruff", "check", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stdout.strip())
        return result.stdout, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ ruff: {e}", True

def run_pylint_check(file_path: str) -> Tuple[str, bool]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç pylint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            ["pylint", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stdout.strip())
        return result.stdout, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ pylint: {e}", True

def check_syntax(file_path: str) -> Tuple[str, bool]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—Å Python —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            [sys.executable, "-m", "py_compile", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stderr.strip())
        return result.stderr, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞: {e}", True

def try_run_code(file_path: str) -> Tuple[str, bool]:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ."""
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(f"""
import sys
import traceback

try:
    with open('{file_path}', 'r') as f:
        code = f.read()
    exec(code)
    print("–ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {{e}}")
    traceback.print_exc()
""")
            temp_path = temp_file.name

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–¥ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
        result = subprocess.run(
            [sys.executable, temp_path],
            capture_output=True,
            text=True,
            timeout=5  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        )
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(temp_path)
        
        has_issues = bool(result.stderr.strip())
        return result.stderr or result.stdout, has_issues
    except subprocess.TimeoutExpired:
        return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (5 —Å–µ–∫—É–Ω–¥)", True
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–æ–¥–∞: {e}", True

def get_ai_recommendations(file_path: str, content: str, model, tokenizer) -> Tuple[str, bool]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞."""
    try:
        prompt = f"""–¢—ã - –æ–ø—ã—Ç–Ω—ã–π Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é. 
–§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞: —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö.

–ö–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
```python
{content}
```

–î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–æ–¥–∞."""

        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        outputs = model.generate(
            **inputs,
            max_new_tokens=500,
            temperature=0.7,
            top_p=0.9,
            do_sample=True
        )
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–ø–æ—Å–ª–µ –ø—Ä–æ–º–ø—Ç–∞)
        recommendations = response.split("–î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–æ–¥–∞.")[-1].strip()
        has_recommendations = bool(recommendations.strip())
        return recommendations, has_recommendations
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}", True

def create_review_comment(pr: PullRequest, file_path: str, ruff_output: str, pylint_output: str, syntax_output: str, run_output: str, ai_recommendations: str):
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ PR —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏."""
    comment = f"""## –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞:
```
{syntax_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ ruff:
```
{ruff_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ pylint:
```
{pylint_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—É—Å–∫–∞ –∫–æ–¥–∞:
```
{run_output}
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:
{ai_recommendations}
"""
    pr.create_issue_comment(comment)

def notify_author(pr: PullRequest, files_with_issues: List[str]):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—É PR –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö."""
    if not files_with_issues:
        return

    author = pr.user.login
    files_list = "\n".join(f"- {file}" for file in files_with_issues)
    
    notification = f"""–ü—Ä–∏–≤–µ—Ç, @{author}! üëã

–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –≤–∞—à PR –∏ –Ω–∞—à–µ–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–º–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç —É–ª—É—á—à–∏—Ç—å:

{files_list}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏, –¥–∞–π—Ç–µ –∑–Ω–∞—Ç—å! ü§ù
"""
    
    pr.create_issue_comment(notification)

def main():
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    github_token = os.getenv("GITHUB_TOKEN")
    
    if not github_token:
        print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω GitHub —Ç–æ–∫–µ–Ω")
        sys.exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º GitHub –∫–ª–∏–µ–Ω—Ç
    g = Github(github_token)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PR
    repo_name = os.getenv("GITHUB_REPOSITORY")
    event_path = os.getenv("GITHUB_EVENT_PATH")
    
    if not event_path:
        print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ–±—ã—Ç–∏—è")
        sys.exit(1)
        
    # –ß–∏—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PR –∏–∑ —Ñ–∞–π–ª–∞ —Å–æ–±—ã—Ç–∏—è
    import json
    with open(event_path, 'r') as f:
        event_data = json.load(f)
        pr_number = event_data['pull_request']['number']
    
    print(f"–ê–Ω–∞–ª–∏–∑ PR #{pr_number}")
    
    repo = g.get_repo(repo_name)
    pr = repo.get_pull(pr_number)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model_name = "microsoft/phi-2"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º phi-2, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ç–æ–∫–µ–Ω–∞
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True
    ).eval()
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    changed_files = get_changed_files(pr)
    files_with_issues = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    for file_path in changed_files:
        if not file_path.endswith('.py'):
            continue
            
        print(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        file_content = repo.get_contents(file_path, ref=pr.head.sha).decoded_content.decode()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
        ruff_output, has_ruff_issues = run_ruff_check(file_path)
        pylint_output, has_pylint_issues = run_pylint_check(file_path)
        syntax_output, has_syntax_issues = check_syntax(file_path)
        run_output, has_run_issues = try_run_code(file_path)
        ai_recommendations, has_ai_recommendations = get_ai_recommendations(file_path, file_content, model, tokenizer)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–æ–∫
        if any([has_ruff_issues, has_pylint_issues, has_syntax_issues, has_run_issues, has_ai_recommendations]):
            files_with_issues.append(file_path)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        create_review_comment(pr, file_path, ruff_output, pylint_output, syntax_output, run_output, ai_recommendations)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—É, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
    if files_with_issues:
        notify_author(pr, files_with_issues)

if __name__ == "__main__":
    main() 