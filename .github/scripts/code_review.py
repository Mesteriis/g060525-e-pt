#!/usr/bin/env python3

import os
import sys
import subprocess
import tempfile
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Tuple
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from github import Github
from github.PullRequest import PullRequest

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∫—ç—à–∞
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)

DEPS_CACHE_DIR = CACHE_DIR / "deps"
DEPS_CACHE_DIR.mkdir(exist_ok=True)

MODEL_CACHE_DIR = CACHE_DIR / "model"
MODEL_CACHE_DIR.mkdir(exist_ok=True)

def get_file_hash(file_path: str, content: str) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—É—Ç–∏ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ."""
    return hashlib.md5(f"{file_path}:{content}".encode()).hexdigest()

def get_deps_hash() -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ pyproject.toml."""
    try:
        with open("pyproject.toml", "r") as f:
            content = f.read()
        return hashlib.md5(content.encode()).hexdigest()
    except:
        return "no_deps"

def get_cached_result(cache_key: str) -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∫—ç—à–∞."""
    cache_file = CACHE_DIR / f"{cache_key}.json"
    if cache_file.exists():
        try:
            with open(cache_file, 'r') as f:
                return json.load(f)
        except:
            return None
    return None

def save_to_cache(cache_key: str, results: Dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—ç—à."""
    cache_file = CACHE_DIR / f"{cache_key}.json"
    with open(cache_file, 'w') as f:
        json.dump(results, f)

def install_dependencies():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    deps_hash = get_deps_hash()
    deps_cache_file = DEPS_CACHE_DIR / f"{deps_hash}.lock"
    
    if deps_cache_file.exists():
        print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
        return
    
    print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
    try:
        subprocess.run(
            [sys.executable, "-m", "pip", "install", "-e", "."],
            check=True,
            capture_output=True
        )
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏
        deps_cache_file.touch()
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {e}")
        sys.exit(1)

def get_changed_files(pr: PullRequest) -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ PR."""
    return [file.filename for file in pr.get_files()]

def run_ruff_check(file_path: str) -> Tuple[str, bool]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç ruff –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            ["ruff", "check", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stdout.strip())
        return result.stdout, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ ruff: {e}", True

def run_pylint_check(file_path: str) -> Tuple[str, bool]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç pylint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            ["pylint", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stdout.strip())
        return result.stdout, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ pylint: {e}", True

def check_syntax(file_path: str) -> Tuple[str, bool]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏–Ω—Ç–∞–∫—Å–∏—Å Python —Ñ–∞–π–ª–∞."""
    try:
        result = subprocess.run(
            [sys.executable, "-m", "py_compile", file_path],
            capture_output=True,
            text=True
        )
        has_issues = bool(result.stderr.strip())
        return result.stderr, has_issues
    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞: {e}", True

def try_run_code(file_path: str) -> Tuple[str, bool]:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ."""
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(f"""
import sys
import traceback

try:
    with open('{file_path}', 'r') as f:
        code = f.read()
    exec(code)
    print("–ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {{e}}")
    traceback.print_exc()
""")
            temp_path = temp_file.name

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–¥ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
        result = subprocess.run(
            [sys.executable, temp_path],
            capture_output=True,
            text=True,
            timeout=5  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        )
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(temp_path)
        
        has_issues = bool(result.stderr.strip())
        return result.stderr or result.stdout, has_issues
    except subprocess.TimeoutExpired:
        return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (5 —Å–µ–∫—É–Ω–¥)", True
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–æ–¥–∞: {e}", True

def get_ai_recommendations(file_path: str, content: str, model, tokenizer) -> Tuple[str, bool]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞."""
    try:
        prompt = f"""<s>[INST] –¢—ã - –æ–ø—ã—Ç–Ω—ã–π Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é. 
–§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞: —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö.

–ö–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
```python
{content}
```

–î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–æ–¥–∞. [/INST]"""

        inputs = tokenizer(prompt, return_tensors="pt")
        if torch.cuda.is_available():
            inputs = inputs.to("cuda")
            model = model.to("cuda")
        
        outputs = model.generate(
            **inputs,
            max_new_tokens=500,
            temperature=0.7,
            top_p=0.9,
            do_sample=True
        )
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–ø–æ—Å–ª–µ –ø—Ä–æ–º–ø—Ç–∞)
        recommendations = response.split("[/INST]")[-1].strip()
        has_recommendations = bool(recommendations.strip())
        return recommendations, has_recommendations
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}", True

def create_review_comment(pr: PullRequest, file_path: str, ruff_output: str, pylint_output: str, syntax_output: str, run_output: str, ai_recommendations: str):
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ PR —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏."""
    comment = f"""## –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞:
```
{syntax_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ ruff:
```
{ruff_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ pylint:
```
{pylint_output}
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—É—Å–∫–∞ –∫–æ–¥–∞:
```
{run_output}
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:
{ai_recommendations}
"""
    pr.create_issue_comment(comment)

def notify_author(pr: PullRequest, files_with_issues: List[str]):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—É PR –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö."""
    if not files_with_issues:
        return

    author = pr.user.login
    files_list = "\n".join(f"- {file}" for file in files_with_issues)
    
    notification = f"""–ü—Ä–∏–≤–µ—Ç, @{author}! üëã

–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –≤–∞—à PR –∏ –Ω–∞—à–µ–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–º–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç —É–ª—É—á—à–∏—Ç—å:

{files_list}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏, –¥–∞–π—Ç–µ –∑–Ω–∞—Ç—å! ü§ù
"""
    
    pr.create_issue_comment(notification)

def main():
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    install_dependencies()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    github_token = os.getenv("GITHUB_TOKEN")
    
    if not github_token:
        print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω GitHub —Ç–æ–∫–µ–Ω")
        sys.exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º GitHub –∫–ª–∏–µ–Ω—Ç
    g = Github(github_token)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PR
    repo_name = os.getenv("GITHUB_REPOSITORY")
    event_path = os.getenv("GITHUB_EVENT_PATH")
    
    if not event_path:
        print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ–±—ã—Ç–∏—è")
        sys.exit(1)
        
    # –ß–∏—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PR –∏–∑ —Ñ–∞–π–ª–∞ —Å–æ–±—ã—Ç–∏—è
    import json
    with open(event_path, 'r') as f:
        event_data = json.load(f)
        pr_number = event_data['pull_request']['number']
    
    print(f"–ê–Ω–∞–ª–∏–∑ PR #{pr_number}")
    
    repo = g.get_repo(repo_name)
    pr = repo.get_pull(pr_number)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º TinyLlama
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True,
        cache_dir=str(MODEL_CACHE_DIR)
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        trust_remote_code=True,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
        cache_dir=str(MODEL_CACHE_DIR)
    ).eval()
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    changed_files = get_changed_files(pr)
    files_with_issues = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    for file_path in changed_files:
        if not file_path.endswith('.py'):
            continue
            
        print(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        file_content = repo.get_contents(file_path, ref=pr.head.sha).decoded_content.decode()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = get_file_hash(file_path, file_content)
        cached_results = get_cached_result(cache_key)
        
        if cached_results:
            print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {file_path}")
            ruff_output = cached_results['ruff_output']
            has_ruff_issues = cached_results['has_ruff_issues']
            pylint_output = cached_results['pylint_output']
            has_pylint_issues = cached_results['has_pylint_issues']
            syntax_output = cached_results['syntax_output']
            has_syntax_issues = cached_results['has_syntax_issues']
            run_output = cached_results['run_output']
            has_run_issues = cached_results['has_run_issues']
            ai_recommendations = cached_results['ai_recommendations']
            has_ai_recommendations = cached_results['has_ai_recommendations']
        else:
            print(f"–í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è {file_path}")
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
            ruff_output, has_ruff_issues = run_ruff_check(file_path)
            pylint_output, has_pylint_issues = run_pylint_check(file_path)
            syntax_output, has_syntax_issues = check_syntax(file_path)
            run_output, has_run_issues = try_run_code(file_path)
            ai_recommendations, has_ai_recommendations = get_ai_recommendations(file_path, file_content, model, tokenizer)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—ç—à
            save_to_cache(cache_key, {
                'ruff_output': ruff_output,
                'has_ruff_issues': has_ruff_issues,
                'pylint_output': pylint_output,
                'has_pylint_issues': has_pylint_issues,
                'syntax_output': syntax_output,
                'has_syntax_issues': has_syntax_issues,
                'run_output': run_output,
                'has_run_issues': has_run_issues,
                'ai_recommendations': ai_recommendations,
                'has_ai_recommendations': has_ai_recommendations
            })
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–æ–∫
        if any([has_ruff_issues, has_pylint_issues, has_syntax_issues, has_run_issues, has_ai_recommendations]):
            files_with_issues.append(file_path)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        create_review_comment(pr, file_path, ruff_output, pylint_output, syntax_output, run_output, ai_recommendations)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—É, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
    if files_with_issues:
        notify_author(pr, files_with_issues)

if __name__ == "__main__":
    main() 